<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto);
        body {
          font-family: 'Roboto';
          /*color: white;*/
          /*background-color: '#000';*/
        }

        h1, h2, h3 {
            /*font-weight: normal;*/
        }


        .footnote {
            position: absolute;
            bottom: 3em;
        }

        .diagram img {
            width: 100%;
        }

        rect.reads {
          fill: red;
          stroke: blue;
          height: 100;
        }

        .mtable table {
          margin-left: auto;
          margin-right: auto;
        }
        .mtable th {
          border-bottom:1px solid #333333;
          /*padding-right: 10px;*/
        }

        .mtable td {
          padding-right: 30px;
        }

        .mtable td:nth-last-child(1) {
          padding-right: 0px;
        }

        .mcode {
          text-align: left;
          margin-left: auto;
          margin-right: auto;
          display: inline-block;
        }

        .cloud img {
          width: 100%;
        }

        .pgexample1-1 tr:nth-child(5) {
          font-weight: bold;
          background-color: black;
          color: white;
        }

        .pgexample1-2 tr:nth-child(12) {
          font-weight: bold;
          background-color: black;
          color: white;
        }

        .mlist {
          width: 50%;
          font-size: 20pt;
          text-align: left;
          margin-left: auto;
          margin-right: auto;
        }
    </style>
  </head>
  <body>
    <textarea id="source">
name: Title
class: center, middle

# A billion rows pet-project on a desktop hardware
#### Alexey Papulovskiy

<br/>

PostgreSQL Conference Europe 2016

Tallinn, Estonia

???
https://remarkjs.com

---
class: center
# PTR

### "Every Internet-reachable host should have a name"

8.8.4.4 → 4.4.8.8.in-addr.arpa → google-public-dns-b.google.com.


???

RFC 1912

PTR - pointer to canonical name, used for determination of a domain name associated with an IP address.

"For every IP address, there should be a matching PTR record in the in-addr.arpa domain."

"Reverse" IP ordering to not to overload DNS-servers

---

class: center
# Why

.mtable[
| IP             | PTR             |
|:---------------|----------------:|
| 173.1.57.105   | mysql1.uber.com |
| 173.1.57.106   | mysql2.uber.com |
| 173.1.57.107   | mongo1.uber.com |
| 173.1.57.108   | mongo2.uber.com |
| 173.204.236.25 | mongo3.uber.com |
| 173.204.236.26 | mysql3.uber.com |
]

???
Security research - many companies reveal infrastructure via reverse DNS

---
class: center
# Why

.mtable[
| IP              | PTR                |
|:----------------|-------------------:|
| 5.9.96.242      | aspmx.l.google.com |
| 8.19.180.13     | aspmx.l.google.com |
| 23.246.203.2    | aspmx.l.google.com |
| 70.168.243.204  | aspmx.l.google.com |
| 80.77.52.162    | aspmx.l.google.com |
| 89.19.28.24     | aspmx.l.google.com |
| 96.27.130.206   | aspmx.l.google.com |
| 108.89.77.153   | aspmx.l.google.com |
| 110.143.19.194  | aspmx.l.google.com |
| 138.201.19.34   | aspmx.l.google.com |
| 146.255.185.92  | aspmx.l.google.com |
| 176.9.108.76    | aspmx.l.google.com |
| 181.170.194.209 | aspmx.l.google.com |
| 190.210.81.241  | aspmx.l.google.com |
| 200.42.6.196    | aspmx.l.google.com |
]

???
Impersonation

---
class: center
# IP v4

## 2<sup>32</sup>

4 294 967 296 possible IP addresses

3 702 258 432 non-reserved IP addresses

1 294 913 005 addresses have pointer records

???

There are reserved blocks of IP addresses

---
class: center

# reverse.report

### Database of pointer records for IPv4 addresses

1 294 913 005 records

100 GB of data

100 GB of indexes

&lt; 20 select requests per second

~ 160 000 000 updates per day

~ 2000 (adjusted) updates per second


???

The goal was to collect data and make it available for searching

---
class: center
# Cloud

.cloud.image[![](assets/cloud.png)]

---

class: center

.cloud.image[![](assets/doghosting_small.png)]

---
class: center
# Desktop hardware

4 cores (8 threads) CPU<!--  @4GHz with 8MB L3 cache -->

64GB non-ECC DDR4 RAM

512GB NVMe SSD

<!-- 1TB SATA SSD -->

4TB Spinning disk

500mbps internet connection

???
TODO: refine
---

title: SSD matters

<!--
  http://jsfiddle.net/gh/get/jquery/1.9.1/highslide-software/highcharts.com/tree/master/samples/highcharts/demo/column-parsed/
-->

.diagram[![SSD IOPS comparison](assets/ssd_chart_log.svg)]

???
Storage revolution

Measured with fio tool (75% reads, 25% writes) on 4GB file.

It's hard to compare environments, so the measurement done just to see the trend, not for absolute values.

Logarithmic scale just to make spinning disk visible

---

title: SSD matters

.diagram[![SSD IOPS comparison](assets/ssd_chart_linear.svg)]

---
class: center

# Scenario #1
### postgresql.org

.mtable[
|       ip        |          name           |
|:----------------|---------------------------:|
|63.246.23.139   | dominion.postgresql.org |
|63.246.23.146   | lore.postgresql.org |
|66.98.251.16    | svr5.postgresql.org |
|66.98.251.159   | svr4.postgresql.org |
|69.168.55.12    | buildfarm.postgresql.org |
|87.238.57.226   | castal.postgresql.org |
|87.238.57.232   | zetar.postgresql.org |
|87.238.57.233   | styris.postgresql.org |
|87.238.57.234   | atalia.postgresql.org |
|174.143.35.130  | relva.postgresql.org |
|174.143.35.244  | procyon.postgresql.org |
|174.143.35.247  | secarus.postgresql.org |
|199.119.121.84  | borg.postgresql.org |
|199.119.121.86  | nausicaa.postgresql.org |
]

---
class: center

# Scenario #1
### postgresql.org

.pgexample1-1.mtable[
|       ip        |          name           |
|:----------------|---------------------------:|
|63.246.23.139   | dominion.postgresql.org |
|63.246.23.146   | lore.postgresql.org |
|66.98.251.16    | svr5.postgresql.org |
|66.98.251.159   | svr4.postgresql.org |
|69.168.55.12    | buildfarm.postgresql.org |
|87.238.57.226   | castal.postgresql.org |
|87.238.57.232   | zetar.postgresql.org |
|87.238.57.233   | styris.postgresql.org |
|87.238.57.234   | atalia.postgresql.org |
|174.143.35.130  | relva.postgresql.org |
|174.143.35.244  | procyon.postgresql.org |
|174.143.35.247  | secarus.postgresql.org |
|199.119.121.84  | borg.postgresql.org |
|199.119.121.86  | nausicaa.postgresql.org |
]

---
class: center

# Scenario #2
### 69.168.55.0/24

.pgexample1-2.mtable[
|      ip       |           name            |
|:--------------|-----------------------------:|
|69.168.55.1   | router-55.colo.spiretech.com |
|69.168.55.2   | 2.55.colo.spiretech.net |
|69.168.55.3   | 3.55.colo.spiretech.net |
|69.168.55.4   | 4.55.colo.spiretech.net |
|69.168.55.5   | 5.55.colo.spiretech.net |
|69.168.55.6   | 6.55.colo.spiretech.net |
|69.168.55.7   | 7.55.colo.spiretech.net |
|69.168.55.8   | 8.55.colo.spiretech.net |
|69.168.55.9   | 9.55.colo.spiretech.net |
|69.168.55.10  | 10.55.colo.spiretech.net |
|69.168.55.11  | 11.55.colo.spiretech.net |
|69.168.55.12  | buildfarm.postgresql.org |
|69.168.55.13  | 13.55.colo.spiretech.net |
|69.168.55.14  | 14.55.colo.spiretech.net |
]

---
class: center

# The Table

---
class: center

# The Table

## ip

---
class: center

# The Table

## ip

### INET

.mcode[
```
# SELECT * FROM rev WHERE ip << '8.8.8.0/24';


    ip    |             name
----------+--------------------------------
 8.8.8.8  | google-public-dns-a.google.com
 8.8.8.14 | localhost
(2 rows)

```]


---
class: center

# The Table

## ip

### INET

### PRIMARY KEY

---
class: center

# The Table

## name


---
class: center

# The Table

## name

### VARCHAR(255)


---
class: center

# The Table

## name

### TEXT

---
class: center

# The Table

## name

### TEXT

> The storage requirement for a short string (up to 126 bytes) is **1** byte plus the actual string, which includes the space padding in the case of character. Longer strings have **4** bytes of overhead instead of **1**.

---
class: center

# The Table

## name

### TEXT

# pg_column_size()

.mcode[
```
       column        | pg_column_size
---------------------+----------------
 000...000exactly120 |            121
 000...000exactly170 |            174
(2 rows)
```
]

---
class: center

# The Table

.mcode[
```
CREATE TABLE rev (
    ip INET PRIMARY KEY,
    name TEXT
);



      Table "public.rev"


   Column   | Type | Modifiers
------------+------+-----------
 ip         | inet | not null
 name       | text |


Indexes:
    "rev_pkey" PRIMARY KEY, btree (ip)

```]


---
class: center

# Collecting data

.mtable[
| ip | name |
|:---|-----:|
| 1.0.5.0   | ip1.ip0.ip5.ip0.reverse.bigredgroup.net.au |
| 1.0.5.1   | ip1.ip0.ip5.ip1.reverse.bigredgroup.net.au |
| 1.0.5.2   | vlan50.hsrp.bigredgroup.net.au |
| 1.0.5.3   | gi2_0_50.brg_mel01_7206.bigredgroup.net.au |
| 1.0.5.4   | ip1.ip0.ip5.ip4.reverse.bigredgroup.net.au |
| 1.0.5.5   | ns2.bigredgroup.net.au |
| 1.0.5.6   | ip1.ip0.ip5.ip6.reverse.bigredgroup.net.au |
| 1.0.5.7   | ip1.ip0.ip5.ip7.reverse.bigredgroup.net.au |
| 1.0.5.8   | ip1.ip0.ip5.ip8.reverse.bigredgroup.net.au |
| 1.0.5.9   | ip1.ip0.ip5.ip9.reverse.bigredgroup.net.au |
| 1.0.5.10  | cloud.totalcloudservice.com.au |
| 1.0.5.11  | ip1.ip0.ip5.ip11.reverse.bigredgroup.net.au |
| 1.0.5.12  | ip1.ip0.ip5.ip12.reverse.bigredgroup.net.au |
| 1.0.5.13  | remote.connective.com.au |
| 1.0.5.14  | ip1.ip0.ip5.ip14.reverse.bigredgroup.net.au |
| 1.0.5.15  | ip1.ip0.ip5.ip15.reverse.bigredgroup.net.au |
]

---
class: center

# Collecting data

.mtable[
| ip | name |
|:---|-----:|
| 1.0.5.**0**   | ip1.ip0.ip5.ip0.reverse.bigredgroup.net.au |
| 1.0.5.**1**   | ip1.ip0.ip5.ip1.reverse.bigredgroup.net.au |
| 1.0.5.**2**   | vlan50.hsrp.bigredgroup.net.au |
| 1.0.5.**3**   | gi2_0_50.brg_mel01_7206.bigredgroup.net.au |
| 1.0.5.**4**   | ip1.ip0.ip5.ip4.reverse.bigredgroup.net.au |
| 1.0.5.**5**   | ns2.bigredgroup.net.au |
| 1.0.5.**6**   | ip1.ip0.ip5.ip6.reverse.bigredgroup.net.au |
| 1.0.5.**7**   | ip1.ip0.ip5.ip7.reverse.bigredgroup.net.au |
| 1.0.5.**8**   | ip1.ip0.ip5.ip8.reverse.bigredgroup.net.au |
| 1.0.5.**9**   | ip1.ip0.ip5.ip9.reverse.bigredgroup.net.au |
| 1.0.5.**10**  | cloud.totalcloudservice.com.au |
| 1.0.5.**11**  | ip1.ip0.ip5.ip11.reverse.bigredgroup.net.au |
| 1.0.5.**12**  | ip1.ip0.ip5.ip12.reverse.bigredgroup.net.au |
| 1.0.5.**13**  | remote.connective.com.au |
| 1.0.5.**14**  | ip1.ip0.ip5.ip14.reverse.bigredgroup.net.au |
| 1.0.5.**15**  | ip1.ip0.ip5.ip15.reverse.bigredgroup.net.au |
]

---
class: center

# Collecting data

.mtable[
| ip | name |
|:---|-----:|
| **1**.0.5.0   | ip1.ip0.ip5.ip0.reverse.bigredgroup.net.au |
| **2**.0.5.0   | anantes-651-1-54-net.w2-0.abo.wanadoo.fr |
| **3**.0.5.0   | n003-000-000-000.static.ge.com |
| **8**.0.5.0   | dns-8-0-5-0.atlanta1.level3.net |
| **23**.0.5.0  | a23-0-5-0.deploy.static.akamaitechnologies.com |
| **24**.0.5.0  | c-24-0-5-0.hsd1.nj.comcast.net |
| **31**.0.5.0  | apn-31-0-5-0.dynamic.gprs.plus.pl |
| **46**.0.5.0  | dynamicip-46-0-5-0.pppoe.samara.ertelecom.ru |
| **50**.0.5.0  | 50-0-5-0.adsl-dhcp.cal.net |
| **52**.0.5.0  | ec2-52-0-5-0.compute-1.amazonaws.com |
| **58**.0.5.0  | ppp-net.infoweb.ne.jp |
| **64**.0.5.0  | 64.0.5.0.ptr.us.xo.net |
| **69**.0.5.0  | 69.0.5.0.adsl.snet.net |
| **70**.0.5.0  | 70-0-5-0.pools.spcsdns.net |
| **71**.0.5.0  | oh-71-0-5-0.dyn.embarqhsd.net |
| **74**.0.5.0  | h-74-0-5-0.phla.pa.globalcapacity.com |
]

---
class: center, middle

# COPY FROM STDIN

---
class: center, middle

# CREATE TABLE new_data AS SELECT * FROM rev LIMIT 0;

---
class: center

# Collecting data

.mlist[
* Buffer responses
* Create intermediate table
* COPY FROM STDIN
* Rename intermediate table
]

---
class: center

# CLUSTER

.left[
> CLUSTER instructs PostgreSQL to cluster the table specified by **table_name** based on the index specified by **index_name**. When a table is clustered, it is physically reordered based on the index information.
]

.mcode[
```
# CLUSTER rev USING rev_pkey;
```
]

???
For selection by networks it's better to have close IPs closer to each other, so there will be less page fetches from disk.

One-time operation, actually rewrites the table.

What happens during update? PTRs a more or less "static", but they actually change and it's better to run cluster again (ACCESS EXCLUSIVE lock → stop updates, create a copy of the table, cluster it, swap tables) from time to time or to specify fillfactor.

TODO: measure

---

class: center

# The Table

.mcode[
```
CREATE TABLE rev (
    ip INET PRIMARY KEY,
    name TEXT
) WITH (
    fillfactor=70
);
```]

<br/>

.mtable[
| | |
|:-|-:|
| Original table | **100**GB |
| Table with fill factor 70 | **130**GB |
]




---
class: center

# Scenario #2

.mcode[
```
# SELECT ip, name FROM rev WHERE name = 'postgresql.org'
  OR name LIKE '%.postgresql.org' LIMIT 10;


      ip       |         reverse
---------------+--------------------------
 63.246.23.146 | lore.postgresql.org
 66.98.251.16  | svr5.postgresql.org
 66.98.251.159 | svr4.postgresql.org
 69.168.55.12  | buildfarm.postgresql.org
 87.238.57.226 | castal.postgresql.org
 87.238.57.227 | feris.postgresql.org
 87.238.57.228 | borka.postgresql.org
 87.238.57.229 | magus.postgresql.org
 87.238.57.230 | straleb.postgresql.org
 87.238.57.231 | meldrar.postgresql.org
(10 rows)

```]

???
Not using btree index, store reversed or use index over reversed value.

---
class: center

# Scenario #2

.mcode[
```
# SELECT ip, name FROM rev WHERE name = reverse('postgresql.org')
  OR name LIKE reverse('%.postgresql.org') LIMIT 10;


      ip       |           name
---------------+--------------------------
 63.246.23.146 | gro.lqsergtsop.erol
 66.98.251.16  | gro.lqsergtsop.5rvs
 66.98.251.159 | gro.lqsergtsop.4rvs
 69.168.55.12  | gro.lqsergtsop.mrafdliub
 87.238.57.226 | gro.lqsergtsop.latsac
 87.238.57.227 | gro.lqsergtsop.siref
 87.238.57.228 | gro.lqsergtsop.akrob
 87.238.57.229 | gro.lqsergtsop.sugam
 87.238.57.230 | gro.lqsergtsop.belarts
 87.238.57.231 | gro.lqsergtsop.rardlem
(10 rows)


```]

???

---
class: center

# Scenario #2

.mcode[
```
# SELECT ip, reverse(name) FROM rev WHERE name = reverse('postgresql.org')
  OR name LIKE reverse('%.postgresql.org') LIMIT 10;


      ip       |         reverse
---------------+--------------------------
 63.246.23.146 | lore.postgresql.org
 66.98.251.16  | svr5.postgresql.org
 66.98.251.159 | svr4.postgresql.org
 69.168.55.12  | buildfarm.postgresql.org
 87.238.57.226 | castal.postgresql.org
 87.238.57.227 | feris.postgresql.org
 87.238.57.228 | borka.postgresql.org
 87.238.57.229 | magus.postgresql.org
 87.238.57.230 | straleb.postgresql.org
 87.238.57.231 | meldrar.postgresql.org
(10 rows)


```]

???
---
class: center

# The Table

.mcode[
```
CREATE TABLE rev (
    ip INET PRIMARY KEY,
    name TEXT
);

CREATE INDEX rev_name_idx
    ON rev (name);
```]

---

class: center

# The Table

.mcode[
```
      Table "public.rev"


   Column   | Type | Modifiers
------------+------+-----------
 ip         | inet | not null
 name       | text |


Indexes:
    "rev_pkey" PRIMARY KEY, btree (ip)
    "rev_name_idx" btree (name)
```
]

???
Two main scenarios
<< inet
subdomains
store reversed strings


Goal: keep everything as simple as possible, no sharding.

---

class: center

# The Table

.mcode[
```
CREATE TABLE rev (
    ip INET PRIMARY KEY,
    name TEXT
) WITH (
    fillfactor=70
);

CREATE INDEX rev_name_idx
    ON rev (name);
```]


---

class: center

# text_pattern_ops

**... values are compared strictly character by character ...**

???
C collation, UTF8

TODO: calculate

# show lc_collate;
 lc_collate
-------------
 en_US.UTF-8
(1 row)

---
class: center

# text_pattern_ops

**... values are compared strictly character by character ...**

## 4 times faster
than default operator classes on pattern matching

???

---

class: center

# The Table

.mcode[
```
CREATE TABLE rev (
    ip INET PRIMARY KEY,
    name TEXT
) WITH (
    fillfactor=70
);

CREATE INDEX rev_name_idx
    ON rev (name text_pattern_ops);
```]

---
class: center

# Tracking updates

.mcode[
```
ALTER TABLE rev ADD COLUMN updated_at DATE;
```
]

<br/>

.mtable[
| ip | name | updated_at |
|:------|:---------|:------|
| fixed | variable | fixed |
]

???
It's better to store all fixed values first, but why?

Experiment with mentioned table structure.

---
class: center

# Type alignment

<br/>

.mtable[
| ip | name | updated_at |
|:------|:---------|:------|
| fixed | variable | fixed |
]

<br/>

.mtable[
| ip | updated_at | name |
|:------|:---------|:------|
| fixed | fixed | variable |
]


---
class: center

# Inserts

<br/>

.mtable[
| ip | name | updated_at |
|:------|:---------|:------|
| fixed | variable | fixed |
]

<br/>

.mtable[
| ip | updated_at | name |
|:------|:---------|:------|
| fixed | fixed | variable |
]

# No winner


---
class: center

# Seq scan by ip

<br/>

.mtable[
| ip | name | updated_at |
|:------|:---------|:------|
| **fixed** | variable | fixed |
]

<br/>

.mtable[
| ip | updated_at | name |
|:------|:---------|:------|
| **fixed** | fixed | variable |
]

# No winner
Results within measurement error.

---
class: center

# Seq scan by updated_at

<br/>

.mtable[
| ip | name | updated_at |
|:------|:---------|:------|
| fixed | variable | **fixed** |
]

<br/>

.mtable[
| ip | updated_at | name |
|:------|:---------|:------|
| fixed | **fixed** | variable |
]

### Second option is about 9% faster


---

class: center

# The Table

.mcode[
```
CREATE TABLE rev (
    ip INET PRIMARY KEY,
    updated_at DATE,
    name TEXT
) WITH (
    fillfactor=70
);

CREATE INDEX rev_name_idx
    ON rev (name varchar_pattern_ops);
```]

---

class: center

# Updates

Python scripts collect data and need to write it fast.

???
Async scripts - it's better to write everything in buffer fast at once to not loose incoming UDP packets.

I can afford losing some update chunks.

---
class: center

# Write amplification

???
TEMPORARY (not for sharing data between processes)
UNLOGGED
LOGGED (regular)


---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_inserts (f1 INT);
# INSERT INTO test_inserts SELECT generate_series(1, 10000000);
```]

### ~359MB

???
It's not the best test for Postgres because of additional 24 bytes per row, but it shows trend.

cat /proc/{}/io | grep ^write_bytes

---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_inserts (f1 INT PRIMARY KEY);
# INSERT INTO test_inserts SELECT generate_series(1, 10000000);
```]

### ~560MB

---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_inserts (f1 INT);
# INSERT INTO test_inserts SELECT generate_series(1, 10000000);
```]

### ~1090MB

---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_inserts (f1 INT PRIMARY KEY);
# INSERT INTO test_inserts SELECT generate_series(1, 10000000);
```]

### ~2054MB

---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_updates (f1 INT);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
```]

### ~360MB

---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_updates (f1 INT);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
```]

### ~780MB


---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_updates (f1 INT);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
# UPDATE test_updates SET f1=f1+10000000;
```]

### ~1280MB


---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_updates (f1 INT);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
# UPDATE test_updates SET f1=f1+10000000;
# UPDATE test_updates SET f1=f1-10000000;
```]

### ~1150MB


---
class: center

# Write amplification

.mcode[```
# CREATE UNLOGGED TABLE test_updates (f1 INT);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
# UPDATE test_updates SET f1=f1+10000000;
# UPDATE test_updates SET f1=f1-10000000;
# UPDATE test_updates SET f1=f1;
```]

### ~1230MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
```]

### ~2070MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
```]

### ~4260MB

---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
# UPDATE test_updates SET f1=f1+10000000;
```]

### ~3900MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# UPDATE test_updates SET f1=f1;
# UPDATE test_updates SET f1=f1+10000000;
# UPDATE test_updates SET f1=f1-10000000;
```]

### ~4620MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# VACUUM FULL test_updates;
# UPDATE test_updates SET f1=f1;
```]

### ~4350MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# VACUUM FULL test_updates;
# UPDATE test_updates SET f1=f1;
# VACUUM FULL test_updates;
# UPDATE test_updates SET f1=f1+10000000;
```]

### ~3430MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY);
# INSERT INTO test_updates SELECT generate_series(1, 10000000);
# VACUUM FULL test_updates;
# UPDATE test_updates SET f1=f1;
# VACUUM FULL test_updates;
# UPDATE test_updates SET f1=f1+10000000;
# VACUUM FULL test_updates;
# UPDATE test_updates SET f1=f1-10000000;
```]

### ~3890MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY, f2 INT);
# INSERT INTO test_updates
    SELECT generate_series(1, 10000000), generate_series(1, 10000000);
```]

### ~2020MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY, f2 INT);
# INSERT INTO test_updates
    SELECT generate_series(1, 10000000), generate_series(1, 10000000);
# UPDATE test_updates SET f2=f2;
```]

### ~4460MB


---
class: center

# Write amplification

.mcode[```
# CREATE TABLE test_updates (f1 INT PRIMARY KEY, f2 INT);
# INSERT INTO test_updates
    SELECT generate_series(1, 10000000), generate_series(1, 10000000);
# UPDATE test_updates SET f2=f2;
# VACUUM test_updates;
# UPDATE test_updates SET f2=f2;
```]

### ~1960MB

???
What about HOT?

---
class: center, middle

# Do not update unchanged data

---
class: center
# Updates

Batches by 100 000 records

<br/>

Python → COPY_FROM → UNLOGGED TABLE

 < 200 ms

<br/>

UNLOGGED TABLE → LOGGED TABLE

15 seconds

---
class: center

# Search

## pg_trgm

GIN (name gin_trgm_ops)

Over 106 mln unique domain names in a separate table (7GB of data, index: 4GB)

???
TODO: comparison between GIST and GIN

Generalized Inverted Index

---
class: center

# Pain

### PG 9.6

.mcode[```
reverse=# VACUUM ANALYZE rev;
VACUUM
Time: 13156379.585 ms
```]

???
3.5 hours

No difference between 9.5 and 9.6 versions, but no one expected.

---
class:center

# Pain
.mcode[```
~$ time pg_dump -Fc --no-unlogged-table-data reverse > ./dumpfile

real    24m58.552s
user    23m50.708s
sys     0m14.676s


~$ time pg_restore -d reverse ./dumpfile

real    298m48.499s
user    6m12.956s
sys     0m36.552s
```]

???
Backup takes 25 minutes, restore takes 5 hours (or 12 on cloud).

---
class: center
# Know your data

---
class: center
# Know your data
# Do not update unchanged data

---
class: center
# Know your data
# Do not update unchanged data
# Read the documentation

---
class: center
# Know your data
# Do not update unchanged data
# Read the documentation
# Experiment

---
class: center
# Know your data
# Do not update unchanged data
# Read the documentation
# Experiment
# Read the documentation again

---

# Database

9.5/9.6

TODO: postgresql.conf settings

---

# Benchmarks

postgres@nvmepg96:~$ pgbench -i -n -q -s 100
NOTICE:  table "pgbench_history" does not exist, skipping
NOTICE:  table "pgbench_tellers" does not exist, skipping
NOTICE:  table "pgbench_accounts" does not exist, skipping
NOTICE:  table "pgbench_branches" does not exist, skipping
creating tables...
9676700 of 10000000 tuples (96%) done (elapsed 5.34 s, remaining 0.18 s)
10000000 of 10000000 tuples (100%) done (elapsed 5.50 s, remaining 0.00 s)
set primary keys...
done.

postgres@nvmepg96:~$ pgbench -t 1000 -c 1
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 100
query mode: simple
number of clients: 1
number of threads: 1
number of transactions per client: 1000
number of transactions actually processed: 1000/1000
latency average = 4.753 ms
tps = 210.376085 (including connections establishing)
tps = 210.439393 (excluding connections establishing)


postgres@nvmepg96:~$ pgbench -t 1000 -c 10
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 100
query mode: simple
number of clients: 10
number of threads: 1
number of transactions per client: 1000
number of transactions actually processed: 10000/10000
latency average = 11.087 ms
tps = 901.943743 (including connections establishing)
tps = 902.049177 (excluding connections establishing)

postgres@nvmepg96:~$ pgbench -t 1000 -c 100
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 100
query mode: simple
number of clients: 100
number of threads: 1
number of transactions per client: 1000
number of transactions actually processed: 100000/100000
latency average = 27.173 ms
tps = 3680.132455 (including connections establishing)
tps = 3680.307017 (excluding connections establishing)


postgres@nvmepg96:~$ pgbench -i -n -q -s 1000
creating tables...
9088300 of 100000000 tuples (9%) done (elapsed 5.00 s, remaining 50.02 s)
9088400 of 100000000 tuples (9%) done (elapsed 5.00 s, remaining 50.02 s)
18580600 of 100000000 tuples (18%) done (elapsed 10.00 s, remaining 43.82 s)
27544600 of 100000000 tuples (27%) done (elapsed 15.00 s, remaining 39.47 s)
37316100 of 100000000 tuples (37%) done (elapsed 20.00 s, remaining 33.60 s)
46566000 of 100000000 tuples (46%) done (elapsed 25.00 s, remaining 28.69 s)
55498800 of 100000000 tuples (55%) done (elapsed 30.00 s, remaining 24.06 s)
64744600 of 100000000 tuples (64%) done (elapsed 35.00 s, remaining 19.06 s)
72365700 of 100000000 tuples (72%) done (elapsed 40.00 s, remaining 15.27 s)
81995600 of 100000000 tuples (81%) done (elapsed 45.00 s, remaining 9.88 s)
91040000 of 100000000 tuples (91%) done (elapsed 50.00 s, remaining 4.92 s)
100000000 of 100000000 tuples (100%) done (elapsed 54.86 s, remaining 0.00 s)
set primary keys...
done.


postgres@nvmepg96:~$ pgbench -t 10000 -c 1
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1000
query mode: simple
number of clients: 1
number of threads: 1
number of transactions per client: 10000
number of transactions actually processed: 10000/10000
latency average = 4.443 ms
tps = 225.084664 (including connections establishing)
tps = 225.092112 (excluding connections establishing)


postgres@nvmepg96:~$ pgbench -t 10000 -c 10
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1000
query mode: simple
number of clients: 10
number of threads: 1
number of transactions per client: 1000
number of transactions actually processed: 10000/10000
latency average = 10.656 ms
tps = 938.465388 (including connections establishing)
tps = 938.577067 (excluding connections establishing)


postgres@nvmepg96:~$ pgbench -t 10000 -c 100
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1000
query mode: simple
number of clients: 100
number of threads: 1
number of transactions per client: 1000
number of transactions actually processed: 100000/100000
latency average = 27.918 ms
tps = 3581.914626 (including connections establishing)
tps = 3582.082283 (excluding connections establishing)


postgres@nvmepg96:~$ pgbench -i -n -q -s 10000
creating tables...
9858700 of 1000000000 tuples (0%) done (elapsed 5.00 s, remaining 502.32 s)
1000000000 of 1000000000 tuples (100%) done (elapsed 545.21 s, remaining 0.00 s)
set primary keys...
done.
postgres@nvmepg96:~$ pgbench -t 10000 -c 1
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 10000
query mode: simple
number of clients: 1
number of threads: 1
number of transactions per client: 10000
number of transactions actually processed: 10000/10000
latency average = 5.001 ms
tps = 199.963435 (including connections establishing)
tps = 199.969233 (excluding connections establishing)

postgres@nvmepg96:~$ pgbench -t 10000 -c 10
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 10000
query mode: simple
number of clients: 10
number of threads: 1
number of transactions per client: 10000
number of transactions actually processed: 100000/100000
latency average = 14.264 ms
tps = 701.056576 (including connections establishing)
tps = 701.062810 (excluding connections establishing)


postgres@nvmepg96:~$ pgbench -t 10000 -c 100
starting vacuum...end.
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 10000
query mode: simple
number of clients: 100
number of threads: 1
number of transactions per client: 10000
number of transactions actually processed: 1000000/1000000
latency average = 38.912 ms
tps = 2569.894441 (including connections establishing)
tps = 2569.904046 (excluding connections establishing)


---

# Data collection

python script
home router (30kpps)
DDoS detector (5kpps)

---


# Updates
Sequencer
Consistency
Unlogged tables
Update rate

---

# Search
trigram

---




# Reads
TODO: sort in query
TODO: recursive queries

---

# Nice features

    </textarea>
    <script src="assets/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
